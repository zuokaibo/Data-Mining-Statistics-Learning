---
title: "HW2"
author: "Bo"
date: "2026-02-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r cars}
fat = read.csv("fat.csv")
head(fat)
```
```{r}
str(fat)
```


```{r pressure, echo=FALSE}
summary(fat)
```


```{r}
library(psych)
```

```{r}
psych::pairs.panels(fat)
```

```{r}
#(a)
n = dim(fat)[1]
n1 = round(n/10)
flag = c(1,21,22,57,70,88,91,94,121,127,149,151,159,162,164,177,179,194,206,214,215,221,240,241,243)
fattrain=fat[-flag, ]
fattest = fat[flag, ]
dim(fattrain)
dim(fattest)
```

```{r}
#(b)
summary(fattrain)
```


```{r}
boxplot(fattrain, main="Box plots for all variables")
```

```{r}
# since the unit of each column is different, they need a normalization.
standardize = function(x){
  z = (x-min(x))/(max(x) - min(x))
  return (z)
}
```

```{r}
fat1train = as.data.frame(apply(fattrain, 2, standardize))
summary(fat1train)
```

```{r}
fat1test = as.data.frame(apply(fattest, 2, standardize))
dim(fat1test)
```

```{r}
boxplot(fat1train, main="Box plot of each normalized variables")
```

```{r}
#(c)
#(i) Linear regression model with all predictors
linear =  lm(brozek~., data=fat1train)
summary(linear)

```

```{r}
#(ii)
LinearFive = lm(brozek~siri+density+weight+free+thigh, data=fat1train)
summary(LinearFive)
```

```{r}
#(iii)
aiclinear = lm(brozek~., data=fat1train)
AIClinear=step(aiclinear, direction="both")
summary(AIClinear)

```

```{r}
#(iv)
library(glmnet)
```
```{r}
# model.matrix() requires x and y input, not a built model. brozek~.means brozek is dependent variable, all else are independent variables.
x = model.matrix(brozek~.,  data=fat1train)
y=fat1train$brozek
```

```{r}
# set alpha = 0 is ridge, 1 is lasso
linear.ridge = glmnet(x, y, alpha = 0)
plot(linear.ridge, xvar="norm", label=TRUE)

cv.ridge = cv.glmnet(x, y, alpha=0)
plot(cv.ridge)
cv.ridge$lambda.min
cv.ridge$lambda.1se

coef(cv.ridge, s=cv.ridge$lambda.1se)
```


```{r}
#(v)lasso
fit.lasso = glmnet(x, y, alpha=1)
plot(fit.lasso, xvar="lambda", label=TRUE)

cv.lasso = cv.glmnet(x,y)
plot(cv.lasso)
cv.lasso$lambda.min
cv.lasso$lambda.1se

coef(cv.lasso, s=cv.lasso$lambda.1se)
```



```{r}
library(pls)
```

```{r}
#(vi)PCR
pcr.model=pcr(brozek~., data=fat1train, validation="CV")
summary(pcr.model)
validationplot(pcr.model, val.type = "MSEP")
validationplot(pcr.model, val.type = "R2")
```

```{r}
#(vii)PLS
pls.model=plsr(brozek~.,data=fat1train, validation="CV")
summary(pls.model)
validationplot(pls.model, val.type="MSEP")
validationplot(pls.model, val.type="R2")
```

```{r}
#(d)
linearprediction = as.data.frame(predict(linear, newdata=fat1test))
#linearprediction
dim(linearprediction)
dim(fat1test)
te.linear = mean(sum((fat1test$brozek - linearprediction)^2))
te.linear
```

```{r}
linearfiveprediction = as.data.frame(predict(LinearFive, newdata=fat1test))
te.linearfive = mean(sum((fat1test$brozek - linearfiveprediction)^2))
te.linearfive
```

```{r}
aic.prediction = as.data.frame(predict(AIClinear, newdata=fat1test))
dim(aic.prediction)
te.aic = mean(sum((fat1test$brozek - aic.prediction)^2))
te.aic
```

```{r}
x.test = model.matrix(brozek~.,  data=fat1test)
y.test = fat1test$brozek
min(linear.ridge$lambda)
```

```{r}
ridge.prediction = as.data.frame(predict(linear.ridge, s=cv.ridge$lambda.1se, newx=x.test))
dim(ridge.prediction)
te.ridge = mean(sum((fat1test$brozek - ridge.prediction)^2))
te.ridge
```

```{r}
lasso.prediction = as.data.frame(predict(fit.lasso, s=cv.lasso$lambda.1se, newx=x.test))
dim(lasso.prediction)
te.lasso=mean(sum((fat1test$brozek - lasso.prediction)^2))
te.lasso
```

```{r}
pcr.predict = as.data.frame(predict(pcr.model, fat1test, ncomp=3))
dim(pcr.predict)
te.pcr=mean(sum((fat1test$brozek - pcr.predict)^2))
te.pcr
```

```{r}
pls.predict=as.data.frame(predict(pls.model, fat1test, ncomp=3))
dim(pls.predict)
te.pls = mean(sum((fat1test$brozek - pls.predict)^2))
te.pls
```

```{r}
tealltrain = NULL
tealltrain = rbind(tealltrain, cbind(te.linear,te.linearfive, te.aic, te.ridge, te.lasso, te.pcr, te.pls))
tealltrain
```

```{r}
set.seed(7406)
```

```{r}
flag = sort(sample(1:n, n1))
fattrain = as.data.frame(fat[-flag, ])
fattest = as.data.frame(fat[flag, ])
dim(fattest)
  
  #linear
linear.mod = lm(brozek~., data=fattrain)
linear.predict = as.data.frame(predict(linear.mod, newdata=fattest))
dim(linear.predict)
linear.te = mean(sum((linear.predict - fattest$brozek)^2))
linear.te

```

```{r}
#TEALL = NULL
#B = 100

#for (b in 1:B) {
#  flag = sort(sample(1:n, n1))
#  fattrain = as.data.frame(fat[-flag, ])
#  fattest = as.data.frame(fat[flag, ])
  
#  fattest = as.data.frame(apply(fattest, 2, standardize))
#  fattrain = as.data.frame(apply(fattrain, 2, standardize))
  
  #linear aic
#  linear.aic = lm(brozek~., data=fattrain)
#  linear.aic.mod = step(linear.aic, direction="both")
#  linear.aic.predict = as.data.frame(predict(linear.aic.mod, newdata=fattest))
#}
#summary(linear.aic.mod)
```


```{r}
# reference from HW1
TEALL = NULL
B = 100

for (b in 1:B) {
  flag = sort(sample(1:n, n1))
  fattrain = as.data.frame(fat[-flag, ])
  fattest = as.data.frame(fat[flag, ])
  
  fattest = as.data.frame(apply(fattest, 2, standardize))
  fattrain = as.data.frame(apply(fattrain, 2, standardize))
  
  
  
  #linear
  linear.mod = lm(brozek~., data=fattrain)
  linear.predict = as.data.frame(predict(linear.mod, newdata=fattest))
  linear.te = mean(sum((linear.predict - fattest$brozek)^2))
  
  #linear with chosen 5 predictiors
  linear.five.mod = lm(brozek~siri+density+weight+free+thigh, data=fattrain)
  linear.five.predict = as.data.frame(predict(linear.five.mod, newdata=fattest))
  linear.five.te = mean(sum((linear.predict - fattest$brozek)^2))
  
  #linear model with lowest aic value obtained from chunk above.(since aic selection takes too many pages to be printed out, so i did a seperate chunk with 100 loops to find best model with lowest aic value, and directly use that best model here.)
  linear.aic.mod = lm(brozek ~ siri + weight + height + adipos + free + thigh + knee + biceps + forearm + wrist,                       data = fattrain)
  linear.aic.predict = as.data.frame(predict(linear.aic.mod, newdata=fattest))
  aic.te = mean(sum((fattest$brozek - linear.aic.predict)^2))
  
  #set up x and y for ridge and lasso regression in glmnet function.
  x.train = model.matrix(brozek~.,  data=fattrain)
  y.train = fattrain$brozek
  x.test = model.matrix(brozek~.,  data=fattest)
  y.test = fattest$brozek
  
  #ridge regression
  ridge.mod = cv.glmnet(x.train, y.train, alpha=0)
  ridge.predict = as.data.frame(predict(ridge.mod, s=ridge.mod$lambda.1se, newx=x.test))
  ridge.te = mean(sum((fattest$brozek - ridge.predict)^2))
  
  #lasso regression
  lasso.mod = cv.glmnet(x.train, y.train, alpha=1)
  lasso.predict = as.data.frame(predict(lasso.mod, s=lasso.mod$lambda.1se, newx=x.test))
  lasso.te = mean(sum((fattest$brozek - lasso.predict)^2))
  
  # pcr regression
  pcr.mod=pcr(brozek~., data=fattrain, validation="CV")
  pcr.predict = as.data.frame(predict(pcr.mod, newdata=fattest, ncomp = 4))
  pcr.te = mean(sum((fattest$brozek - pcr.predict)^2))
  #validationplot(pcr.mod, val.type = "R2")
  
  #pls regression
  pls.mod=plsr(brozek~.,data=fattrain, validation="CV")
  pls.predict = as.data.frame(predict(pls.mod, newdata=fattest, ncomp = 3))
  #validationplot(pls.mod, val.type = "R2")
  pls.te = mean(sum((fattest$brozek - pls.predict)^2))
  
  TEALL = rbind(TEALL, cbind(linear.te, linear.five.te, aic.te, ridge.te, lasso.te, pcr.te, pls.te))
}

```


```{r}
#print(TEALL)
```


```{r}
apply(TEALL, 2, mean)
```


```{r}
apply(TEALL, 2, var)
```



